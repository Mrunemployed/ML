{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3470b1c-417c-4718-82af-b34e6dbcd74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4da7b-da9e-421d-bb37-b41cea3c309e",
   "metadata": {},
   "source": [
    "# Scaling the features of the training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff48c32-efb8-4457-aa2d-9e865547da69",
   "metadata": {},
   "source": [
    "> ### Note\n",
    "> Scaling the features helps optimize the Gradient descent algorithm by making the features more consistent\n",
    "> and shortens the iterations requried.\n",
    "> We have used the Z-Score normalization method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e060a72-40f1-40d9-9846-730ece6083b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscale(x):\n",
    "    mu = np.mean(x, axis=0) # axis 0 will make the resultant array have shape n,\n",
    "    sigma = np.std(x, axis=0)\n",
    "    x_scaled = (x - mu)/sigma\n",
    "    return x_scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001af0ea-762e-48b7-bae9-9a9bf790e29d",
   "metadata": {},
   "source": [
    "# Compute the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eea1ea7-02e6-47f9-a4d2-93457867a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w,x,b):\n",
    "    z = np.dot(w,x)+b\n",
    "    g_z = 1/(1+np.exp(-z))\n",
    "    return g_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415daf7-f00f-44a7-8201-99ecae185a59",
   "metadata": {},
   "source": [
    "# Classic Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645e961-2b27-4605-b90f-ac9fead82823",
   "metadata": {},
   "source": [
    "**Compute the gradient of the Logistic function using Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16cb6acf-8cbb-4f57-bb64-3467f77da082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(w,b,x,y):\n",
    "    m,n = x.shape\n",
    "    dw = np.zeros((n,))\n",
    "    db = 0.\n",
    "    for i in range(m):\n",
    "        gz = sigmoid(w,x[i],b)\n",
    "        error = gz-y[i]\n",
    "        for j in range(n):\n",
    "            dw[j] += error*x[i][j]\n",
    "        db += error\n",
    "    return dw/m,db/m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142bf2df-09bb-44e1-9ba2-59e20ff39507",
   "metadata": {},
   "source": [
    "## Classic Logistic Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3602a7-3aa1-4d94-9ee6-4fe2a0ddba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_cost(w,x,y,b):\n",
    "    m,n = x.shape\n",
    "    j_wb = 0\n",
    "    for i in range(m):\n",
    "        gz = sigmoid(w,x[i],b)\n",
    "        cost = -y[i]*np.log(gz)-((1-y[i])*(np.log(1-gz)))\n",
    "        j_wb += cost\n",
    "    j_wb = j_wb/m\n",
    "    return j_wb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ab470-1ed7-4baa-82bb-e92ee4985bad",
   "metadata": {},
   "source": [
    "## Calculate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5461f7ba-5f04-4373-a546-1567a0fcf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(itr,x,y):\n",
    "    alpha = 1.0e-2\n",
    "    m,n = x.shape\n",
    "    w = np.zeros((n,))\n",
    "    b = 0.\n",
    "    dw = np.zeros((n,))\n",
    "    db = 0.\n",
    "    for i in range(itr):\n",
    "        dw,db = gradient(w,b,x,y)\n",
    "        w = w - alpha*dw\n",
    "        b = b - alpha*db\n",
    "        if int(i % 100) == 0:\n",
    "            print(f\"w: {w}, b: {b}\")\n",
    "            cost = logistic_cost(w,x,y,b)\n",
    "            print(\"cost: \",cost)\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a3f88c-c005-472b-9f45-239cd40ece0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [-0.0029545  -0.00471772  0.00442478  0.00315503  0.00249769  0.00162223], b: -0.001\n",
      "cost:  0.6861386003513423\n",
      "w: [-0.18774614 -0.34886977  0.31892753  0.19488185  0.1588771   0.12397961], b: -0.08920357867993883\n",
      "cost:  0.33623936808471955\n",
      "w: [-0.26881559 -0.56219425  0.50390217  0.27116815  0.22467647  0.19997175], b: -0.15801306362222645\n",
      "cost:  0.22773889451779214\n",
      "w: [-0.31489877 -0.72033197  0.63616358  0.30928749  0.25901874  0.25413939], b: -0.2130019082357987\n",
      "cost:  0.17421421832255485\n",
      "w: [-0.34557102 -0.84747527  0.73985797  0.33105225  0.27990855  0.29608184], b: -0.25798258919566847\n",
      "cost:  0.14156747979749057\n",
      "w: [-0.36814177 -0.95428165  0.82534733  0.34452418  0.29416167  0.33027148], b: -0.29549040462712994\n",
      "cost:  0.11934367220906358\n",
      "w: [-0.38591378 -1.0465353   0.89810977  0.35330662  0.30478878  0.35911908], b: -0.32728188190340557\n",
      "cost:  0.1031721826179262\n",
      "w: [-0.40058398 -1.12779367  0.96143667  0.35922572  0.31326793  0.38406542], b: -0.3546115910574494\n",
      "cost:  0.09085858503471074\n",
      "w: [-0.41311016 -1.2004268   1.01747732  0.36329354  0.32038451  0.40603843], b: -0.37839663564338377\n",
      "cost:  0.08116490911666821\n",
      "w: [-0.42407391 -1.26610306  1.06771898  0.36611023  0.32658319  0.42567024], b: -0.3993208129471111\n",
      "cost:  0.07333473604670826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.43375711, -1.32547096,  1.11280111,  0.3680351 ,  0.33207678,\n",
       "         0.44324147]),\n",
       " -0.41772745403816447)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the features first.\n",
    "np.random.seed(1)\n",
    "X_tmp = np.random.rand(5,6)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "x_scaled = fscale(X_tmp)\n",
    "w,b = logistic_regression(1000,x_scaled,y_tmp)\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7545a0-e5c2-4d12-8ad1-416cf31628f2",
   "metadata": {},
   "source": [
    "#### The Cost gradually decreases and something along the following result will be displayed\n",
    "\n",
    "```\n",
    "w: [-0.0029545  -0.00471772  0.00442478  0.00315503  0.00249769  0.00162223], b: -0.001\n",
    "cost:  0.6861386003513423\n",
    "w: [-0.18774614 -0.34886977  0.31892753  0.19488185  0.1588771   0.12397961], b: -0.08920357867993883\n",
    "cost:  0.33623936808471955\n",
    "w: [-0.26881559 -0.56219425  0.50390217  0.27116815  0.22467647  0.19997175], b: -0.15801306362222645\n",
    "cost:  0.22773889451779214\n",
    "w: [-0.31489877 -0.72033197  0.63616358  0.30928749  0.25901874  0.25413939], b: -0.2130019082357987\n",
    "cost:  0.17421421832255485\n",
    "w: [-0.34557102 -0.84747527  0.73985797  0.33105225  0.27990855  0.29608184], b: -0.25798258919566847\n",
    "cost:  0.14156747979749057\n",
    "w: [-0.36814177 -0.95428165  0.82534733  0.34452418  0.29416167  0.33027148], b: -0.29549040462712994\n",
    "cost:  0.11934367220906358\n",
    "w: [-0.38591378 -1.0465353   0.89810977  0.35330662  0.30478878  0.35911908], b: -0.32728188190340557\n",
    "cost:  0.1031721826179262\n",
    "w: [-0.40058398 -1.12779367  0.96143667  0.35922572  0.31326793  0.38406542], b: -0.3546115910574494\n",
    "cost:  0.09085858503471074\n",
    "w: [-0.41311016 -1.2004268   1.01747732  0.36329354  0.32038451  0.40603843], b: -0.37839663564338377\n",
    "cost:  0.08116490911666821\n",
    "w: [-0.42407391 -1.26610306  1.06771898  0.36611023  0.32658319  0.42567024], b: -0.3993208129471111\n",
    "cost:  0.07333473604670826\n",
    "(array([-0.43375711, -1.32547096,  1.11280111,  0.3680351 ,  0.33207678,\n",
    "         0.44324147]),\n",
    " -0.41772745403816447)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17657e2-f3dd-449c-a8da-3ba247a2de15",
   "metadata": {},
   "source": [
    "# Logistic Regression (Regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bcee0-e63c-4e0f-a7e4-0c63669ab092",
   "metadata": {},
   "source": [
    "> The **sigmoid function** remains unchanged\n",
    "> \n",
    "> The changes are made to the **Gradient descent algorithm** and the **logistic cost function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7fbc77-42d5-4925-a266-80282a298f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_gradient(x,y,w,b,lamd):\n",
    "    m,n = x.shape\n",
    "    dw = np.zeros((n,))\n",
    "    db = 0.\n",
    "    for i in range(m):\n",
    "        error = sigmoid(w,x[i],b) - y[i]\n",
    "        for j in range(n):\n",
    "            dw[j] = dw[j]+error*x[i][j]\n",
    "        db+= error\n",
    "    dw = dw/m\n",
    "    db = db/m\n",
    "    dw = dw + (lamd/m)*w\n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac6a401f-3fa5-42c6-b2dd-05fcd60a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_cost(w,b,x,y,lamd):\n",
    "    m,n = x.shape\n",
    "    cost = 0.\n",
    "    for i in range(m):\n",
    "        # (-i/m)sum(y(log(f_wb(x)) + (1-y)(log(f_wb(x))) +lambda/2m(sum(wj^2)))\n",
    "        gz = sigmoid(w,x[i],b)\n",
    "        cost+= -y[i]*np.log(gz) - (1-y[i])*(np.log(1-gz))\n",
    "        # print(f\"cost calculation: -y[i]*np.log(gz) - (1-y)*(np.log(1-gz))= {y[i]}*{np.log(gz)}+{(1-y)}*{np.log(1-gz)}\")\n",
    "    cost = cost/2*m\n",
    "    su_wj = np.sum(w**2)\n",
    "    reg_exp = (lamd/2*m)*su_wj\n",
    "    cost = cost + reg_exp\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e57a2758-f265-48a1-bef7-6e23b93b5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_gradient_desc(x,y,itr):\n",
    "    m,n = x.shape\n",
    "    dw = np.zeros((n,))\n",
    "    w = np.zeros((n,))\n",
    "    b = 0.\n",
    "    db = 0.\n",
    "    lamd = 1.3\n",
    "    alpha = 1e-3\n",
    "    for i in range(itr):\n",
    "        # print(f\"function to be called: reg_gradient({x},{y},{w},{b},{lamd})\")\n",
    "        dw,db = reg_gradient(x,y,w,b,lamd)\n",
    "        w = w - alpha*dw\n",
    "        b = b - alpha*db\n",
    "        if i%100 == 0:\n",
    "            cost = reg_logistic_cost(w,b,x,y,lamd)\n",
    "            print(f\"cost : {cost}\")\n",
    "            print(f\"w: {w}, b: {b}\")\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe994829-39db-4290-bbe4-95e1c7d1a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[ 0.19097825  0.39716945 -0.8603242  -0.6362233  -1.25338677 -1.84606008]\n",
      " [-0.65458148 -0.92024644  0.44266862  0.11063051  1.0767403   0.39215012]\n",
      " [-0.58792203  0.95186269 -0.77073255  0.52640416  1.06057788 -0.08551748]\n",
      " [-0.8226708  -1.43861337  1.76972053  1.46688419  0.17210233  0.4189654 ]\n",
      " [ 1.87419605  1.00982766 -0.58133239 -1.46769556 -1.05603375  1.12046205]], \n",
      "y: [0 1 0 1 0]\n",
      "cost : 8.655547186827633\n",
      "w: [-0.00029545 -0.00047177  0.00044248  0.0003155   0.00024977  0.00016222], b: -0.0001\n",
      "cost : 7.878464644583944\n",
      "w: [-0.02795541 -0.04535207  0.04242379  0.0297786   0.02365176  0.0156793 ], b: -0.009974719081439489\n",
      "cost : 7.273264143635377\n",
      "w: [-0.05219722 -0.08602457  0.08025696  0.05545615  0.04419361  0.02988888], b: -0.01960489342398975\n",
      "cost : 6.801554424744762\n",
      "w: [-0.07346543 -0.12297215  0.11442546  0.0778414   0.06223788  0.04291684], b: -0.028995551311076177\n",
      "cost : 6.433292270239045\n",
      "w: [-0.09216002 -0.1566321   0.14536813  0.09737992  0.07811002  0.0548786 ], b: -0.038152045717318006\n",
      "cost : 6.145284688324362\n",
      "w: [-0.10863129 -0.18739037  0.17347262  0.11446274  0.09209597  0.06587858], b: -0.04708041644667105\n",
      "cost : 5.919734368560816\n",
      "w: [-0.12318118 -0.21558254  0.19907605  0.12942717  0.10444372  0.0760104 ], b: -0.05578739017693442\n",
      "cost : 5.742997722864411\n",
      "w: [-0.13606767 -0.24149829  0.22246911  0.14256136  0.11536685  0.08535757], b: -0.06428021103945068\n",
      "cost : 5.604591844010618\n",
      "w: [-0.14751032 -0.26538695  0.24390173  0.15411042  0.1250487   0.09399436], b: -0.0725664257341815\n",
      "cost : 5.496428210279794\n",
      "w: [-0.15769585 -0.28746316  0.26358868  0.16428255  0.13364653  0.10198677], b: -0.08065368552077043\n"
     ]
    }
   ],
   "source": [
    "#Scaling the features first.\n",
    "np.random.seed(1)\n",
    "X_tmp = np.random.rand(5,6)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "# print(f\"x: {X_tmp}, \\ny: {y_tmp}\")\n",
    "x_scaled = fscale(X_tmp)\n",
    "print(f\"x: {x_scaled}, \\ny: {y_tmp}\")\n",
    "w,b = reg_logistic_gradient_desc(x_scaled,y_tmp,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483836f-eb55-46d0-a896-3478650ebc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
